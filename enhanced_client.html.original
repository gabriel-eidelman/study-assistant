<!DOCTYPE html>
<html>

<!-- Add WebGazer.js library -->


<head>
    <title>Enhanced Study Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
        }
        .video-container {
            margin-bottom: 20px;
            position: relative;
        }
        #videoElement {
            width: 640px;
            height: 480px;
            background-color: #ddd;
            border: 1px solid #999;
        }
        #faceMeshCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 640px;
            height: 480px;
        }
        #activityCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 640px;
            height: 480px;
            opacity: 0.4;
        }
        button {
            padding: 10px 15px;
            margin: 5px;
            cursor: pointer;
        }
        #results {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            min-height: 100px;
            max-height: 200px;
            overflow-y: auto;
            white-space: pre-wrap;
        }
        .metrics {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 20px;
        }
        .metric-card {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            min-width: 150px;
            background-color: #f9f9f9;
        }
        .suggestion {
            background-color: #e6f7ff;
            border-left: 4px solid #1890ff;
            padding: 10px;
            margin-top: 15px;
        }
        .note {
            background-color: #fff7e6;
            border-left: 4px solid #ffa940;
            padding: 10px;
            margin-bottom: 15px;
        }
        .debug-panel {
            margin-top: 15px;
            padding: 10px;
            background-color: #f0f0f0;
            border: 1px solid #ddd;
        }
        .stat-value {
            font-weight: bold;
        }
        #loadingMessage {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            padding: 10px;
            background-color: #e6f7ff;
            color: #1890ff;
            text-align: center;
            z-index: 1000;
        }
        .error {
            color: red;
            font-weight: bold;
            padding: 10px;
            background-color: #fff1f0;
            border-left: 4px solid #ff4d4f;
            margin-bottom: 15px;
        }
        .tracking-status {
            padding: 5px 10px;
            border-radius: 15px;
            font-weight: bold;
            display: inline-block;
            margin-left: 10px;
        }
        .status-active {
            background-color: #52c41a;
            color: white;
        }
        .status-fallback {
            background-color: #faad14;
            color: white;
        }
        .status-inactive {
            background-color: #f5222d;
            color: white;
        }
        .tabs {
            margin-top: 20px;
            border-bottom: 1px solid #ccc;
        }
        .tab {
            display: inline-block;
            padding: 8px 15px;
            cursor: pointer;
            border: 1px solid transparent;
            border-bottom: none;
            margin-bottom: -1px;
        }
        .tab-active {
            border-color: #ccc;
            border-radius: 5px 5px 0 0;
            background-color: white;
        }
        .tab-content {
            display: none;
            padding: 15px;
            border: 1px solid #ccc;
            border-top: none;
        }
        .tab-content-active {
            display: block;
        }
        .session-summary {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #d9d9d9;
            border-radius: 5px;
            background-color: #f5f5f5;
        }
        .status-gaze {
            background-color: #1890ff;
            color: white;
        }
        #calibration-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.7);
            z-index: 1000;
            display: none;
        }
        #notification {
            position: fixed;
            top: 10px;
            left: 50%;
            transform: translateX(-50%);
            background-color: #4CAF50;
            color: white;
            padding: 10px 20px;
            border-radius: 5px;
            z-index: 2000;
            opacity: 0;
            transition: opacity 0.5s;
        }
    </style>
    <!-- Face-api.js from CDN -->
    

    <!-- Face and Gaze Detection Libraries -->
    <script src="/static/face-api.min.js"></script>
    <script>
        // Add window.updateTrackingStatus function for gaze-tracking.js to use
        window.updateTrackingStatus = function(mode) {
            window.currentTrackingMode = mode;
            
            if (window.trackingModeElement) {
                window.trackingModeElement.textContent = mode;
            }
            
            // Update status indicator
            if (window.trackingStatus) {
                window.trackingStatus.className = 'tracking-status';
                
                switch(mode) {
                    case 'gaze':
                        window.trackingStatus.textContent = 'Gaze Tracking';
                        window.trackingStatus.classList.add('status-active');
                        break;
                    case 'face':
                        window.trackingStatus.textContent = 'Face Tracking';
                        window.trackingStatus.classList.add('status-active');
                        break;
                    case 'motion':
                        window.trackingStatus.textContent = 'Motion Tracking';
                        window.trackingStatus.classList.add('status-fallback');
                        break;
                    case 'memory':
                        window.trackingStatus.textContent = 'Memory Tracking';
                        window.trackingStatus.classList.add('status-fallback');
                        break;
                    case 'inactive':
                        window.trackingStatus.textContent = 'Inactive';
                        window.trackingStatus.classList.add('status-inactive');
                        break;
                    default:
                        window.trackingStatus.textContent = mode;
                        window.trackingStatus.classList.add('status-inactive');
                }
            }
        };
    </script>
    
    <!-- Load WebGazer after face-api.js to avoid conflicts -->
    <script src="https://webgazer.cs.brown.edu/webgazer.js"></script>
    
    <!-- Load gaze-tracking.js last -->
    <script src="/static/gaze-tracking.js"></script>
</head>
<body>
    <div id="loadingMessage" style="display: none;">Loading face detection models... Please wait.</div>
    
    <div class="container">
        <h1>Enhanced Study Assistant</h1>
        
        <div id="errorMessage" class="error" style="display: none;"></div>
        
        <div class="note">
            <strong>Improved Version:</strong> This client uses enhanced face tracking that works even when looking away from camera, 
            with motion detection as a fallback. When face detection is unavailable, the system continues to monitor based on last known position and activity detection.
        </div>
        
        <div class="video-container">
            <video id="videoElement" autoplay muted></video>
            <canvas id="faceMeshCanvas"></canvas>
            <canvas id="activityCanvas"></canvas>
        </div>
        
        <div class="controls">
            <button id="startSessionBtn">Start Study Session</button>
            <button id="pauseSessionBtn" disabled>Pause Session</button>
            <button id="resumeSessionBtn" disabled>Resume Session</button>
            <button id="endSessionBtn" disabled>End Session</button>
            <button id="settingsBtn">Settings</button>
        </div>
        
        <div class="status">
            <p>Status: <span id="statusText">Not started</span> <span id="trackingStatus" class="tracking-status">Inactive</span></p>
            <p>Session ID: <span id="sessionId">None</span></p>
            <p>Time Elapsed: <span id="sessionTimer">00:00:00</span> | Effective Study Time: <span id="effectiveTimer">00:00:00</span></p>
        </div>
        
        <div class="tabs">
            <div class="tab tab-active" data-tab="metrics">Metrics</div>
            <div class="tab" data-tab="insights">Insights</div>
            <div class="tab" data-tab="debug">Debug</div>
        </div>
        
        <div id="metrics-tab" class="tab-content tab-content-active">
            <div class="metrics">
                <div class="metric-card">
                    <h3>Focus</h3>
                    <p id="focusMetric">-</p>
                </div>
                <div class="metric-card">
                    <h3>Gaze Tracking</h3>
                    <p id="gazeMetric">Not calibrated</p>
                    <p>Content attention: <span id="contentAttentionValue" class="stat-value">-</span>%</p>
                </div>
                <div class="metric-card">
                    <h3>Blink Rate</h3>
                    <p id="blinkMetric">-</p>
                    <p>Last minute: <span id="blinkRateValue" class="stat-value">-</span> blinks/min</p>
                </div>
                <div class="metric-card">
                    <h3>Head Position</h3>
                    <p id="headPoseMetric">-</p>
                </div>
                <div class="metric-card">
                    <h3>Activity</h3>
                    <p id="activityMetric">-</p>
                </div>
            </div>
            
            <div id="suggestion" class="suggestion" style="display: none;">
                No suggestions yet
            </div>
        </div>
        
        <div id="insights-tab" class="tab-content">
            <h3>Session Insights</h3>
            <p>Study insights will appear here during and after your session.</p>
            <div id="insights-content"></div>
        </div>
        
        <div id="debug-tab" class="tab-content">
            <div class="debug-panel">
                <h3>Tracking Metrics:</h3>
                <p>Last blink: <span id="lastBlinkTime">-</span></p>
                <p>Blink count: <span id="blinkCounter">0</span></p>
                <p>Eye aspect ratio: <span id="eyeAspectRatio">-</span></p>
                <p>Gaze position: <span id="gazePosition">-</span></p>
                <p>Looking at content: <span id="lookingAtContent">-</span></p>
                <p>Face detection FPS: <span id="faceDetectionFPS">-</span></p>
                <p>Current tracking mode: <span id="trackingMode">None</span></p>
                <p>Motion level: <span id="motionLevel">0</span></p>
                <p>Keyboard/mouse events: <span id="inputEvents">0</span></p>
            </div>
            
            <h3>Results:</h3>
            <div id="results">Results will appear here...</div>
        </div>
        
        <div id="settings-modal" style="display: none; position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.5); z-index: 1000;">
            <div style="position: relative; width: 500px; margin: 100px auto; background-color: white; padding: 20px; border-radius: 5px;">
                <h2>Study Assistant Settings</h2>
                
                <h3>Face Detection Settings</h3>
                <div>
                    <label>Face detection confidence threshold:</label>
                    <input type="range" id="faceConfidenceSlider" min="0.1" max="0.9" step="0.1" value="0.3">
                    <span id="faceConfidenceValue">0.3</span>
                </div>
                
                <div>
                    <label>Eye aspect ratio threshold (blink detection):</label>
                    <input type="range" id="earThresholdSlider" min="0.1" max="0.5" step="0.05" value="0.2">
                    <span id="earThresholdValue">0.2</span>
                </div>
                
                <h3>Fallback Detection Settings</h3>
                <div>
                    <label>Motion detection sensitivity:</label>
                    <input type="range" id="motionSensitivitySlider" min="5" max="50" step="5" value="15">
                    <span id="motionSensitivityValue">15</span>
                </div>
                
                <div>
                    <label>Face memory duration (seconds):</label>
                    <input type="range" id="faceMemorySlider" min="1" max="10" step="1" value="3">
                    <span id="faceMemoryValue">3</span>
                </div>
                
                <h3>Display Settings</h3>
                <div>
                    <label>
                        <input type="checkbox" id="showFaceMeshCheckbox" checked> 
                        Show face mesh overlay
                    </label>
                </div>
                
                <div>
                    <label>
                        <input type="checkbox" id="showMotionOverlayCheckbox" checked> 
                        Show motion detection overlay
                    </label>
                </div>
                
                <div style="margin-top: 20px; text-align: right;">
                    <button id="closeSettingsBtn">Save & Close</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        const API_URL = 'http://localhost:8000';
        let currentSessionId = null;
        let sessionStartTime = null;
        let effectiveStudyStartTime = null;
        let effectiveStudyTime = 0;
        let isPaused = false;
        let sessionTimer = null;
        let effectiveTimer = null;
        
        // Face detection variables
        let isModelLoaded = false;
        let lastEyeRatio = 1.0;
        let eyesClosed = false;
        let blinkCount = 0;
        let lastBlinkTime = Date.now();
        let blinkRates = [];
        let lastFrameTime = Date.now();
        let faceDetectionTimes = [];
        let lastDetectedFace = null;
        let lastFaceDetectionTime = 0;
        let currentTrackingMode = 'inactive';
        let prevFrame = null;
        let motionDetected = false;
        let motionLevel = 0;
        let inputEventCount = 0;
        let lastInputEventTime = 0;
        // Gaze tracking variables

        // Settings with defaults
        let settings = {
            faceDetectionConfidence: 0.3,     // Lower than original to detect faces at more extreme angles
            eyeAspectRatioThreshold: 0.2,     // Threshold for blink detection
            motionSensitivity: 15,            // Sensitivity for motion detection
            faceMemoryDuration: 3,            // How long to remember the last detected face position (seconds)
            showFaceMesh: true,               // Whether to show face mesh overlay
            showMotionOverlay: true           // Whether to show motion detection overlay
        };
        
        // DOM elements
        window.video = document.getElementById('videoElement');
        window.canvas = document.getElementById('faceMeshCanvas');
        window.activityCanvas = document.getElementById('activityCanvas');
        const startBtn = document.getElementById('startSessionBtn');
        const pauseBtn = document.getElementById('pauseSessionBtn');
        const resumeBtn = document.getElementById('resumeSessionBtn');
        const endBtn = document.getElementById('endSessionBtn');
        const settingsBtn = document.getElementById('settingsBtn');
        const closeSettingsBtn = document.getElementById('closeSettingsBtn');
        const statusText = document.getElementById('statusText');
        const trackingStatus = document.getElementById('trackingStatus');
        const sessionIdElement = document.getElementById('sessionId');
        const sessionTimerElement = document.getElementById('sessionTimer');
        const effectiveTimerElement = document.getElementById('effectiveTimer');
        const resultsDiv = document.getElementById('results');
        const suggestionDiv = document.getElementById('suggestion');
        const focusMetric = document.getElementById('focusMetric');
        const blinkMetric = document.getElementById('blinkMetric');
        const blinkRateValue = document.getElementById('blinkRateValue');
        const headPoseMetric = document.getElementById('headPoseMetric');
        const activityMetric = document.getElementById('activityMetric');
        const lastBlinkTimeElement = document.getElementById('lastBlinkTime');
        const blinkCounterElement = document.getElementById('blinkCounter');
        const eyeAspectRatioElement = document.getElementById('eyeAspectRatio');
        const faceDetectionFPSElement = document.getElementById('faceDetectionFPS');
        const loadingMessage = document.getElementById('loadingMessage');
        const errorMessage = document.getElementById('errorMessage');
        const trackingModeElement = document.getElementById('trackingMode');
        const motionLevelElement = document.getElementById('motionLevel');
        const inputEventsElement = document.getElementById('inputEvents');
        const insightsContent = document.getElementById('insights-content');

        // Settings DOM elements
        const faceConfidenceSlider = document.getElementById('faceConfidenceSlider');
        const faceConfidenceValue = document.getElementById('faceConfidenceValue');
        const earThresholdSlider = document.getElementById('earThresholdSlider');
        const earThresholdValue = document.getElementById('earThresholdValue');
        const motionSensitivitySlider = document.getElementById('motionSensitivitySlider');
        const motionSensitivityValue = document.getElementById('motionSensitivityValue');
        const faceMemorySlider = document.getElementById('faceMemorySlider');
        const faceMemoryValue = document.getElementById('faceMemoryValue');
        const showFaceMeshCheckbox = document.getElementById('showFaceMeshCheckbox');
        const showMotionOverlayCheckbox = document.getElementById('showMotionOverlayCheckbox');
        const settingsModal = document.getElementById('settings-modal');
        // Gaze tracking DOM elements
        const gazeMetric = document.getElementById('gazeMetric');
        const contentAttentionValue = document.getElementById('contentAttentionValue');
        const gazePosition = document.getElementById('gazePosition');
        const lookingAtContent = document.getElementById('lookingAtContent');
        // Tab functionality
        const tabs = document.querySelectorAll('.tab');
        const tabContents = document.querySelectorAll('.tab-content');
        
        tabs.forEach(tab => {
            tab.addEventListener('click', () => {
                const tabName = tab.getAttribute('data-tab');
                
                // Remove active class from all tabs and contents
                tabs.forEach(t => t.classList.remove('tab-active'));
                tabContents.forEach(c => c.classList.remove('tab-content-active'));
                
                // Add active class to clicked tab and corresponding content
                tab.classList.add('tab-active');
                document.getElementById(`${tabName}-tab`).classList.add('tab-content-active');
            });
        });
        
        // Show an error message
        function showError(message) {
            errorMessage.textContent = message;
            errorMessage.style.display = 'block';
            console.error(message);
        }
        
        // Hide the error message
        function hideError() {
            errorMessage.style.display = 'none';
        }
        
        // Initialize face-api.js with lower detection threshold
        // Replace the existing initFaceAPI function with this improved version
// Place this in the <script> section of enhanced_client.html

async function initFaceAPI() {
    try {
        loadingMessage.style.display = 'block';
        statusText.textContent = 'Loading face detection models...';
        hideError();
        
        // First, check if faceapi is defined
        if (typeof faceapi === 'undefined') {
            console.log('faceapi is not defined. Attempting to load the library dynamically...');
            
            // Try to load the face-api.js dynamically
            return new Promise((resolve, reject) => {
                const script = document.createElement('script');
                script.src = 'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2';
                script.onload = async () => {
                    console.log('face-api.js loaded dynamically');
                    
                    // Now that the library is loaded, continue with model loading
                    try {
                        await loadFaceDetectionModels();
                        resolve(true);
                    } catch (modelErr) {
                        reject(modelErr);
                    }
                };
                script.onerror = (err) => {
                    reject(new Error('Failed to load face-api.js library dynamically'));
                };
                document.head.appendChild(script);
            });
        } else {
            // Library is already loaded, just load the models
            return await loadFaceDetectionModels();
        }
    } catch (err) {
        loadingMessage.style.display = 'none';
        showError(`Error during model loading: ${err.message}`);
        statusText.textContent = 'Error loading face detection models';
        return false;
    }
}

// Add this new function to handle the model loading separately
async function loadFaceDetectionModels() {
    // Set the models URL to the static directory
    const modelUrl = '/static/models';
    
    console.log(`Loading models from ${modelUrl}`);
    
    try {
        // Load the face detection models sequentially with error handling for each
        console.log('Loading TinyFaceDetector model...');
        await faceapi.loadTinyFaceDetectorModel(modelUrl)
            .catch(err => {
                throw new Error(`Failed to load TinyFaceDetector model: ${err.message}`);
            });
        console.log('Loaded TinyFaceDetector model');
        
        console.log('Loading FaceLandmark model...');
        await faceapi.loadFaceLandmarkModel(modelUrl)
            .catch(err => {
                throw new Error(`Failed to load FaceLandmark model: ${err.message}`);
            });
        console.log('Loaded FaceLandmark model');
        
        // If we got here, all models loaded successfully
        loadingMessage.style.display = 'none';
        statusText.textContent = 'Face detection models loaded';
        console.log('All face detection models loaded successfully');
        isModelLoaded = true;
        
        return true;
    } catch (error) {
        loadingMessage.style.display = 'none';
        showError(`Model loading error: ${error.message}`);
        console.error('Face model loading error:', error);
        return false;
    }
}

window.startWebcam = async function() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
                width: { ideal: 640 },
                height: { ideal: 480 },
                facingMode: "user"
            } 
        });
        video.srcObject = stream;
        
        // Initialize face detection after webcam is ready
        video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            activityCanvas.width = video.videoWidth;
            activityCanvas.height = video.videoHeight;
            
            // Initialize face detection
            initFaceAPI().then(async (success) => {
                // After face API is initialized, try initializing gaze tracking
                if (success) {
                    const gazeInitialized = await initializeGazeTracking();
                    if (gazeInitialized) {
                        gazeMetric.textContent = 'Ready for calibration';
                    }
                }
                
                // Start processing frames with the enhanced version
                requestAnimationFrame(enhancedProcessFrame);
            }).catch(err => {
                console.error('Face API initialization error:', err);
                showError(`Face detection initialization failed: ${err.message}`);
                requestAnimationFrame(enhancedProcessFrame);
            });
        };
    } catch (err) {
        console.error('Error accessing webcam:', err);
        resultsDiv.textContent = 'Error accessing webcam: ' + err.message;
        showError(`Cannot access webcam: ${err.message}. Please ensure camera permissions are enabled for this page.`);
    }
}
        
        // Calculate eye aspect ratio (EAR) - to detect blinks
        function calculateEyeAspectRatio(eye) {
            // Euclidean distance between two points
            function euclideanDist(pt1, pt2) {
                return Math.sqrt(Math.pow(pt2.x - pt1.x, 2) + Math.pow(pt2.y - pt1.y, 2));
            }
            
            // Calculate the height of the eye (average of two vertical measurements)
            const h1 = euclideanDist(eye[1], eye[5]);
            const h2 = euclideanDist(eye[2], eye[4]);
            
            // Calculate the width of the eye
            const w = euclideanDist(eye[0], eye[3]);
            
            // Calculate EAR
            // EAR = (h1 + h2) / (2 * w)
            if (w === 0) return 1.0; // Avoid division by zero
            return (h1 + h2) / (2 * w);
        }
        
        // Detect motion between frames
        window.detectMotion = function(currentFrame) {
            if (!prevFrame || !currentFrame) return 0;
            
            const ctxCurrent = document.createElement('canvas').getContext('2d');
            ctxCurrent.canvas.width = video.videoWidth;
            ctxCurrent.canvas.height = video.videoHeight;
            ctxCurrent.drawImage(video, 0, 0, ctxCurrent.canvas.width, ctxCurrent.canvas.height);
            
            // Sample pixels at lower resolution for performance
            const sampleStep = 10;
            const width = ctxCurrent.canvas.width;
            const height = ctxCurrent.canvas.height;
            
            let totalDiff = 0;
            let sampleCount = 0;
            
            // Get current frame data
            const currentData = ctxCurrent.getImageData(0, 0, width, height).data;
            
            // Compare with previous frame
            for (let y = 0; y < height; y += sampleStep) {
                for (let x = 0; x < width; x += sampleStep) {
                    const idx = (y * width + x) * 4;
                    
                    // Calculate pixel difference
                    const diff = Math.abs(currentData[idx] - prevFrame[idx]) + 
                                Math.abs(currentData[idx+1] - prevFrame[idx+1]) + 
                                Math.abs(currentData[idx+2] - prevFrame[idx+2]);
                    
                    totalDiff += diff;
                    sampleCount++;
                }
            }
            
            // Calculate average difference
            const avgDiff = totalDiff / (sampleCount * 3); // 3 color channels
            
            // Visualize motion if enabled
            if (settings.showMotionOverlay) {
                const ctxActivity = activityCanvas.getContext('2d');
                ctxActivity.clearRect(0, 0, activityCanvas.width, activityCanvas.height);
                
                if (avgDiff > settings.motionSensitivity) {
                    // Draw motion heat map
                    ctxActivity.fillStyle = `rgba(255, 0, 0, ${Math.min(avgDiff / 100, 0.3)})`;
                    ctxActivity.fillRect(0, 0, activityCanvas.width, activityCanvas.height);
                }
            }
            
            // Store current frame as previous for next comparison
            prevFrame = currentData;
            
            return avgDiff;
        }
        
        // Calculate head orientation from landmarks
        window.calculateHeadOrientation = function(landmarks) {
            // Get key points
            const nose = landmarks.getNose()[0];  // Nose tip
            const leftEye = landmarks.getLeftEye();
            const rightEye = landmarks.getRightEye();
            
            // Calculate eye midpoints
            const leftEyeMidX = leftEye.reduce((sum, pt) => sum + pt.x, 0) / leftEye.length;
            const leftEyeMidY = leftEye.reduce((sum, pt) => sum + pt.y, 0) / leftEye.length;
            const rightEyeMidX = rightEye.reduce((sum, pt) => sum + pt.x, 0) / rightEye.length;
            const rightEyeMidY = rightEye.reduce((sum, pt) => sum + pt.y, 0) / rightEye.length;
            
            // Calculate eye midpoint
            const eyeMidX = (leftEyeMidX + rightEyeMidX) / 2;
            const eyeMidY = (leftEyeMidY + rightEyeMidY) / 2;
            
            // Calculate horizontal distance between eyes
            const eyeDistance = Math.sqrt(
                Math.pow(rightEyeMidX - leftEyeMidX, 2) + 
                Math.pow(rightEyeMidY - leftEyeMidY, 2)
            );
            
            // Calculate horizontal difference (yaw indicator)
            const horizontalDiff = nose.x - eyeMidX;
            const yaw = (horizontalDiff / eyeDistance) * 45;  // Scale to approximate degrees
            
            // Calculate vertical difference (pitch indicator)
            const verticalDiff = nose.y - eyeMidY;
            const pitch = (verticalDiff / eyeDistance) * 30;  // Scale to approximate degrees
            
            // Update head pose metric based on orientation
            if (Math.abs(yaw) > 20) {
                headPoseMetric.textContent = `Looking ${yaw > 0 ? 'right' : 'left'} ⚠️`;
            } else if (pitch > 15) {
                headPoseMetric.textContent = 'Looking down ⚠️';
            } else if (pitch < -10) {
                headPoseMetric.textContent = 'Looking up ⚠️';
            } else {
                headPoseMetric.textContent = 'Forward-facing ✓';
            }
            
            return { yaw, pitch };
        }
        
        // Start a new study session
        async function startSession() {
            try {
                const response = await fetch(`${API_URL}/start-session/`, {
                    method: 'POST'
                });
                
                const data = await response.json();
                currentSessionId = data.session_id;
                
                statusText.textContent = 'Session active';
                sessionIdElement.textContent = currentSessionId;
                
                // Update UI
                startBtn.disabled = true;
                pauseBtn.disabled = false;
                resumeBtn.disabled = true;
                endBtn.disabled = false;
                
                // Reset metrics and counters
                blinkCount = 0;
                blinkRates = [];
                inputEventCount = 0;
                blinkCounterElement.textContent = blinkCount;
                focusMetric.textContent = 'Monitoring...';
                blinkMetric.textContent = 'Monitoring...';
                headPoseMetric.textContent = 'Monitoring...';
                activityMetric.textContent = 'Monitoring...';
                
                // Reset session timers
                sessionStartTime = Date.now();
                effectiveStudyStartTime = Date.now();
                effectiveStudyTime = 0;
                
                // Start session timers
                sessionTimer = setInterval(updateSessionTimer, 1000);
                
                // Hide suggestion initially
                suggestionDiv.style.display = 'none';
                
                resultsDiv.textContent = JSON.stringify(data, null, 2);
                
                // Clear insights
                insightsContent.innerHTML = '';
                addInsight('Study session started');
                
                // The frame processing loop is already running
            } catch (err) {
                console.error('Error starting session:', err);
                resultsDiv.textContent = 'Error starting session: ' + err.message;
                showError(`Error starting session: ${err.message}. Make sure the API server is running at ${API_URL}`);
            }
        }
        
        // Pause the current session
        function pauseSession() {
            if (!currentSessionId || isPaused) return;
            
            isPaused = true;
            statusText.textContent = 'Session paused';
            
            // Update button states
            pauseBtn.disabled = true;
            resumeBtn.disabled = false;
            
            // Stop effective study timer but keep session timer running
            const now = Date.now();
            effectiveStudyTime += (now - effectiveStudyStartTime);
            
            // Add insight
            addInsight('Session paused');
        }
        
        // Resume the current session
        function resumeSession() {
            if (!currentSessionId || !isPaused) return;
            
            isPaused = false;
            statusText.textContent = 'Session active';
            
            // Update button states
            pauseBtn.disabled = false;
            resumeBtn.disabled = true;
            
            // Reset effective study start time
            effectiveStudyStartTime = Date.now();
            
            // Add insight
            addInsight('Session resumed');
        }
        
        // Update the session timer display
        function updateSessionTimer() {
            if (!sessionStartTime) return;
            
            const now = Date.now();
            const sessionElapsed = now - sessionStartTime;
            
            // Format total session time
            const sessionHours = Math.floor(sessionElapsed / (1000 * 60 * 60));
            const sessionMinutes = Math.floor((sessionElapsed % (1000 * 60 * 60)) / (1000 * 60));
            const sessionSeconds = Math.floor((sessionElapsed % (1000 * 60)) / 1000);
            
            sessionTimerElement.textContent = 
                `${String(sessionHours).padStart(2, '0')}:${String(sessionMinutes).padStart(2, '0')}:${String(sessionSeconds).padStart(2, '0')}`;
            
            // Calculate effective study time
            let effectiveElapsed = effectiveStudyTime;
            if (!isPaused) {
                effectiveElapsed += (now - effectiveStudyStartTime);
            }
            
            // Format effective study time
            const effectiveHours = Math.floor(effectiveElapsed / (1000 * 60 * 60));
            const effectiveMinutes = Math.floor((effectiveElapsed % (1000 * 60 * 60)) / (1000 * 60));
            const effectiveSeconds = Math.floor((effectiveElapsed % (1000 * 60)) / 1000);
            
            effectiveTimerElement.textContent = 
                `${String(effectiveHours).padStart(2, '0')}:${String(effectiveMinutes).padStart(2, '0')}:${String(effectiveSeconds).padStart(2, '0')}`;
        }
        
        // End the current study session
        async function endSession() {
            if (!currentSessionId) return;
            
            try {
                // Stop timers
                clearInterval(sessionTimer);
                isPaused = true;
                
                // Calculate effective study time if was active
                if (!isPaused) {
                    const now = Date.now();
                    effectiveStudyTime += (now - effectiveStudyStartTime);
                }
                
                const response = await fetch(`${API_URL}/end-session/${currentSessionId}`, {
                    method: 'POST'
                });
                
                const data = await response.json();
                
                // Display session summary
                let summaryHTML = `<h3>Study Session Summary</h3>
                    <p>Duration: ${data.duration_minutes.toFixed(2)} minutes</p>
                    <p>Distraction events: ${data.distraction_count}</p>
                    <p>Average focus period: ${data.average_focus_period_minutes.toFixed(2)} minutes</p>
                    <p>Posture changes: ${data.posture_change_count}</p>`;
                    
                if (data.average_blink_rate !== null) {
                    summaryHTML += `<p>Average blink rate: ${data.average_blink_rate.toFixed(1)} blinks/minute</p>`;
                }
                
                if (data.suggestions && data.suggestions.length > 0) {
                    summaryHTML += '<h4>Suggestions for next time:</h4><ul>';
                    data.suggestions.forEach(suggestion => {
                        summaryHTML += `<li>${suggestion}</li>`;
                    });
                    summaryHTML += '</ul>';
                }
                
                // Create a session summary element
                const summaryDiv = document.createElement('div');
                summaryDiv.className = 'session-summary';
                summaryDiv.innerHTML = summaryHTML;
                
                // Add to insights
                insightsContent.prepend(summaryDiv);
                
                // Also show in suggestion area
                suggestionDiv.innerHTML = summaryHTML;
                suggestionDiv.style.display = 'block';
                
                // Add to debug console
                resultsDiv.textContent = JSON.stringify(data, null, 2);
                
                statusText.textContent = 'Session ended';
                
                // Reset UI
                startBtn.disabled = false;
                pauseBtn.disabled = true;
                resumeBtn.disabled = true;
                endBtn.disabled = true;
                
                // Reset session state
                currentSessionId = null;
                sessionIdElement.textContent = 'None';
                sessionStartTime = null;
                effectiveStudyStartTime = null;
                effectiveStudyTime = 0;
                
                // Clear canvas
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                const actCtx = activityCanvas.getContext('2d');
                actCtx.clearRect(0, 0, activityCanvas.width, activityCanvas.height);
                
                // Switch to insights tab
                document.querySelector('.tab[data-tab="insights"]').click();
                
                // Hide any error messages
                hideError();
            } catch (err) {
                console.error('Error ending session:', err);
                resultsDiv.textContent = 'Error ending session: ' + err.message;
                showError(`Error ending session: ${err.message}`);
            }
        }
        
        // Track keyboard and mouse events
        function trackInputEvents() {
            const updateInputEvents = () => {
                inputEventCount++;
                lastInputEventTime = Date.now();
                inputEventsElement.textContent = inputEventCount;
            };
            
            // Add event listeners to document for keyboard and mouse events
            document.addEventListener('keydown', updateInputEvents);
            document.addEventListener('mousemove', () => {
                // Only count significant mouse movements
                if (Math.random() < 0.1) { // Sample to avoid too many events
                    updateInputEvents();
                }
            });
            document.addEventListener('click', updateInputEvents);
        }
        
        // Settings functionality
        function initSettings() {
            // Initialize settings values
            faceConfidenceSlider.value = settings.faceDetectionConfidence;
            faceConfidenceValue.textContent = settings.faceDetectionConfidence;
            
            earThresholdSlider.value = settings.eyeAspectRatioThreshold;
            earThresholdValue.textContent = settings.eyeAspectRatioThreshold;
            
            motionSensitivitySlider.value = settings.motionSensitivity;
            motionSensitivityValue.textContent = settings.motionSensitivity;
            
            faceMemorySlider.value = settings.faceMemoryDuration;
            faceMemoryValue.textContent = settings.faceMemoryDuration;
            
            showFaceMeshCheckbox.checked = settings.showFaceMesh;
            showMotionOverlayCheckbox.checked = settings.showMotionOverlay;
            
            // Add event listeners for settings controls
            faceConfidenceSlider.addEventListener('input', () => {
                settings.faceDetectionConfidence = parseFloat(faceConfidenceSlider.value);
                faceConfidenceValue.textContent = settings.faceDetectionConfidence;
            });
            
            earThresholdSlider.addEventListener('input', () => {
                settings.eyeAspectRatioThreshold = parseFloat(earThresholdSlider.value);
                earThresholdValue.textContent = settings.eyeAspectRatioThreshold;
            });
            
            motionSensitivitySlider.addEventListener('input', () => {
                settings.motionSensitivity = parseInt(motionSensitivitySlider.value);
                motionSensitivityValue.textContent = settings.motionSensitivity;
            });
            
            faceMemorySlider.addEventListener('input', () => {
                settings.faceMemoryDuration = parseInt(faceMemorySlider.value);
                faceMemoryValue.textContent = settings.faceMemoryDuration;
            });
            
            showFaceMeshCheckbox.addEventListener('change', () => {
                settings.showFaceMesh = showFaceMeshCheckbox.checked;
            });
            
            showMotionOverlayCheckbox.addEventListener('change', () => {
                settings.showMotionOverlay = showMotionOverlayCheckbox.checked;
                
                // Update the visibility of activity canvas based on setting
                activityCanvas.style.display = settings.showMotionOverlay ? 'block' : 'none';
            });
            
            // Settings modal toggle
            settingsBtn.addEventListener('click', () => {
                settingsModal.style.display = 'block';
            });
            
            closeSettingsBtn.addEventListener('click', () => {
                settingsModal.style.display = 'none';
                
                // Save settings to localStorage
                localStorage.setItem('studyAssistantSettings', JSON.stringify(settings));
            });
            
            // Load settings from localStorage if available
            const savedSettings = localStorage.getItem('studyAssistantSettings');
            if (savedSettings) {
                try {
                    const parsedSettings = JSON.parse(savedSettings);
                    settings = { ...settings, ...parsedSettings };
                    
                    // Update UI with loaded settings
                    faceConfidenceSlider.value = settings.faceDetectionConfidence;
                    faceConfidenceValue.textContent = settings.faceDetectionConfidence;
                    
                    earThresholdSlider.value = settings.eyeAspectRatioThreshold;
                    earThresholdValue.textContent = settings.eyeAspectRatioThreshold;
                    
                    motionSensitivitySlider.value = settings.motionSensitivity;
                    motionSensitivityValue.textContent = settings.motionSensitivity;
                    
                    faceMemorySlider.value = settings.faceMemoryDuration;
                    faceMemoryValue.textContent = settings.faceMemoryDuration;
                    
                    showFaceMeshCheckbox.checked = settings.showFaceMesh;
                    showMotionOverlayCheckbox.checked = settings.showMotionOverlay;
                } catch (e) {
                    console.error('Error loading saved settings:', e);
                }
            }
        }
        
        // Event listeners
        startBtn.addEventListener('click', startSession);
        pauseBtn.addEventListener('click', pauseSession);
        resumeBtn.addEventListener('click', resumeSession);
        endBtn.addEventListener('click', endSession);
        
        // Initialize
        startWebcam();
        trackInputEvents();
        initSettings();
    </script>
</body>
</html>